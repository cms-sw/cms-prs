{"additions": 229, "auther_ref": "CUDAService_verbosity", "auther_sha": "1a5a3456cb5024bff91361f2d47492288aca1a90", "author": "fwyzard", "body": "#### PR description:\r\n\r\nAdd the NVIDIA driver, CUDA driver and runtime library versions to the `CUDAService` message.\r\nMake the `CUDAService` less verbose by default, with an option to display the full messages, and enable it in the `MessageLogger` by default.\r\n\r\n#### PR validation:\r\n\r\nThe default, compact message on a machine with two GPUs now looks like\r\n```\r\nCUDA runtime version 11.2, driver version 11.4, NVIDIA driver version 470.57.02\r\nCUDA device 0: Tesla T4 (sm_75)\r\nCUDA device 1: Tesla T4 (sm_75)\r\n```\r\n\r\nThe full, verbose message on the same machine now looks like\r\n```\r\nNVIDIA driver:    470.57.02\r\nCUDA driver API:  11.4 (compiled with 11.2)\r\nCUDA runtime API: 11.2 (compiled with 11.2)\r\nCUDA runtime successfully initialised, found 2 compute devices.\r\n\r\nCUDA device 0: Tesla T4\r\n  compute capability:          7.5 (sm_75)\r\n  streaming multiprocessors:            40\r\n  CUDA cores:                         2560\r\n  single to double performance:       32:1\r\n  compute mode:           default (shared)\r\n  memory:  15009 MB free /  15109 MB total\r\n  constant memory:                   64 kB\r\n  L2 cache size:                   4096 kB\r\n  L1 cache mode:   local and global memory\r\n\r\nOther capabilities\r\n  can map host memory into the CUDA address space for use with cudaHostAlloc()/cudaHostGetDevicePointer()\r\n  does not support coherently accessing pageable memory without calling cudaHostRegister() on it\r\n  cannot access pageable memory via the host's page tables\r\n  can access host registered memory at the same virtual address as the host\r\n  shares a unified address space with the host\r\n  supports allocating managed memory on this system\r\n  can coherently access managed memory concurrently with the host\r\n  the host cannot directly access managed memory on the device without migration\r\n  supports launching cooperative kernels via cudaLaunchCooperativeKernel()\r\n  supports launching cooperative kernels via cudaLaunchCooperativeKernelMultiDevice()\r\n\r\nCUDA flags\r\n  thread policy:                   default\r\n  pinned host memory allocations:  enabled\r\n  kernel host memory reuse:       disabled\r\n\r\nCUDA limits\r\n  printf buffer size:                 1 MB\r\n  stack size:                         1 kB\r\n  malloc heap size:                   8 MB\r\n  runtime sync depth:                    2\r\n  runtime pending launch count:       2048\r\n\r\nCUDA device 1: Tesla T4\r\n  compute capability:          7.5 (sm_75)\r\n  streaming multiprocessors:            40\r\n  CUDA cores:                         2560\r\n  single to double performance:       32:1\r\n  compute mode:           default (shared)\r\n  memory:  15009 MB free /  15109 MB total\r\n  constant memory:                   64 kB\r\n  L2 cache size:                   4096 kB\r\n  L1 cache mode:   local and global memory\r\n\r\nOther capabilities\r\n  can map host memory into the CUDA address space for use with cudaHostAlloc()/cudaHostGetDevicePointer()\r\n  does not support coherently accessing pageable memory without calling cudaHostRegister() on it\r\n  cannot access pageable memory via the host's page tables\r\n  can access host registered memory at the same virtual address as the host\r\n  shares a unified address space with the host\r\n  supports allocating managed memory on this system\r\n  can coherently access managed memory concurrently with the host\r\n  the host cannot directly access managed memory on the device without migration\r\n  supports launching cooperative kernels via cudaLaunchCooperativeKernel()\r\n  supports launching cooperative kernels via cudaLaunchCooperativeKernelMultiDevice()\r\n\r\nCUDA flags\r\n  thread policy:                   default\r\n  pinned host memory allocations:  enabled\r\n  kernel host memory reuse:       disabled\r\n\r\nCUDA limits\r\n  printf buffer size:                 1 MB\r\n  stack size:                         1 kB\r\n  malloc heap size:                   8 MB\r\n  runtime sync depth:                    2\r\n  runtime pending launch count:       2048\r\n\r\nCUDAService fully initialized\r\n```", "branch": "master", "changed_files": 8, "comments": 40, "commits": 6, "created_at": "1630534393", "deletions": 101, "labels": ["hlt-pending", "operations-pending", "pending-signatures", "orp-pending", "tests-started", "requires-external", "code-checks-approved", "heterogeneous-pending"], "milestone": "CMSSW_12_1_X", "number": 35117, "release-notes": [], "review_comments": 5, "state": "open", "title": "CUDAService verbosity", "updated_at": "1631821823", "user": "fwyzard"}