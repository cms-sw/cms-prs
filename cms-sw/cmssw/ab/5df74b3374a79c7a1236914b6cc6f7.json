{"additions": 3001, "auther_ref": "dqm-prepare-for-stream-v4", "auther_sha": "2f51722c107e3813da767d6ce5adbf49bc818cbb", "author": "schneiml", "body": "#### PR description:\r\nThis PR depends on many previous PR *and contains them*. Integration will take a while. [Edit: All dependencies are in!. Should be good to go now.]\r\n\r\nThis PR completely replaces the Core DQM infrastructure. Some things don't change, but are re-implemented. This state was achieved in previous pull requests:\r\n- DQM Histograms are stored and managed by `edm::Service<DQMStore>`.\r\n     - Using a service makes things like online DQM and the DQM@HLT protobuf chain easier, since we can ask the `DQMStore` for a snapshot of the current histograms.\r\n     - Using a service is required to handle job-level products, which we need for multi-run harvesting (and for historical reasons also normal harvesting). \r\n    - Using a service allows legacy modules to work unchanged.\r\n\r\n- In non-legacy modules, all dependencies across the the `DQMStore` are passed to edm via `DQMToken` products, that do not contain any data. (As far as possible -- there are no job products, so the job-level dependencies cannot be expressed.)\r\n    - The tokens are divided into 4 _generations_: `DQMGenerationReco`, `DQMGenerationHarvesting`, `DQMGenerationQTest`, denoted in the instance label.\r\n    - `DQMGenerationReco` is produced by `DQMEDAnalyzer`s, which consume only \"normal\" (non-DQM) products.\r\n    - `DQMGenerationHarvesting` is produced by `DQMEDHarvester`s, which consume (by default) all `DQMGenerationReco` tokens. This allows all old code to work without explicitly declaring dependencies. `DQMEDHarvester`s provide a mechanism to consume more specific tokens, including `DQMGenerationHarvesting` tokens from other harvesters.\r\n    - `DQMGenerationQTest` is produced only by the `QualityTester` module (of which we typically have many instances). The `QualityTester` has fully configurable dependencies to allow the more complicated setups sometimes required in harvesting, but typically consumes `DQMGenerationHarvesting`.\r\n    - There is a hidden dependency between end run and end job in harvesting: Many harvesters effectively depend on `DQMGenerationQTest` products (the QTest results) and do not specify that, but things still work because they do their work in `endJob`.\r\n\r\n- There are six supported types of DQM modules:\r\n    - `DQMEDAnalyzer`, based on `edm::one::EDProducer`. Used for the majority of histogram filling in RECO jobs. Soon to be based on `edm::stream`.\r\n    - `DQMOneEDAnalyzer` based on `edm::one::EDProducer`. Used when begin/end job transitions are required. Can accept more `edm::one` specific options. Cannot save per-lumi histograms.\r\n    - `DQMOneLumiEDAnalyzer` based on `edm::one::EDProducer`. Used when begin/end lumi transitions are needed. Blocks concurrent lumisections.\r\n    - `DQMGlobalEDAnalyzer` based on `edm::global::EDProducer`. Used for DQM@HLT and a few random other things. Cannot save per-lumi histograms (this is a conflict with the fact that HLT _typically_ saves _only_ per lumi histograms, see #28341).\r\n    - `DQMEDHarvester` based on `edm::one::EDProducer`. Used in harvesting jobs to manipulate histograms in lumi, run, and job transitions. \r\n    - `edm::EDAnalyzer` legacy modules. Can do filling and harvesting. Not safe to use in the presence of concurrent lumisections. Safe for multi-threaded running from the DQM framework side.\r\n- There are four supported file formats for DQM histograms:\r\n    - DQMIO, `TTree` based ROOT files. Reading and writing implemented in EDM input and output modules in `DQMServices/FwkIO`: `DQMRootSource` and `DQMRootOutputModule`.\r\n    - Legacy `TDirectory` based `DQM_*.root` ROOT files. Only write support, implemented in `DQMServices/Core` (see  #28588). Read support dropped in this PR, unneeded since references where removed. Only this format supports saving JOB histograms.\r\n    - ProtoBuf streamer, a.k.a. `fastHadd` files. Implemented by `DQMFileSaverPB`/`DQMFileSaver` (see #11086) and the edm input module `DQMProtobufReader`, in \"streamer\" format for HLT/DAQ.\r\n    - `MEtoEDM` edm based files. Read and written by the Pool I/O modules, after copying `DQMStore` content to edm products using `MEtoEDMConverter`.\r\n\r\nIn this PR, the following features are implemented/modified:\r\n- Mode-less `DQMStore`. While there where many different modes before (`enableMultiThread`, `lsBasedMode`, `forceResetOnLumi`, `collate`, etc.) that could be configured in various ways and changed the behavior of the `DQMStore` (sometimes fundamentally, making certain features only work in certain modes), the new DQMStore has only a single mode. \r\n    - There are two options to control per-lumi saving (`saveByLumi` in the `DQMStore`) and harvesting (`reScope` in `DQMRootSource`). Both can be expressed in terms of _Scope_, see later.\r\n    - Another option, `assertLegacySafe`, only adds assertions to make sure no operations that would be unsafe in the presence of legacy modules sneak in. It does not affect the behaviour.\r\n    - The `verbose` option should not affect the behavior, though it has in the past (if only due to race conditions).\r\n- Data-race free. The new implementation tries very hard to prevent data races even when legacy APIs are used, using fine-grained locking. \r\n    - This does not mean that there are no race conditions. Whenever histograms are read while they are being filled in a multi-threaded context, the results can be dependent on thread interleaving. But, there should be no undefined behavior on C++ level.\r\n    - For safe manipulation of ROOT objects during booking, a callback interface is provided.\r\n    - Currently, there is still only one global `IBooker` and booking methods cannot run concurrently, but it is easy to change this now (will probably be allowed with the `edm::stream` modules).\r\n- _Global_ and _local_ histograms for concurrent lumisections.\r\n    - In the DQM API, we face the conflict that `MonitorElement` objects are held in the modules (so their life cycle has to match that of the module) but also represent histograms whose life cycle depends the data processed (run and lumi transitions). This caused conflicts since the introduction of multi-threading.\r\n    - The new `DQMStore` resolves this conflict by representing each monitor element using (at least) two objects: A _local_ `MonitorElement`, that follows the module life cycle but does not own data, and a _global_ `MonitorElement` that owns histogram data but does not belong to any module. There may be multiple _local_ MEs for one _global_ ME if multiple modules fill the same histogram (`edm::stream` or even independent modules). There may be multiple _global_ MEs for the same histogram if there are concurrent lumisections.\r\n    - The live cycle of _local_ MEs is driven by callbacks from each of the module base classes (`enterLumi`, `leaveLumi`). For legacy `edm::EDAnalyzer`s, global begin/end run/lumi hooks are used, which only work as long as there are no concurrent lumisections. The _local_ MEs are kept in a set of containers indexed by the `moduleID`, with special value `0` for _all_ legacy modules and special values for `DQMGlobalEDAnalyzer`s, where the local MEs need to match the life cycle of the `runCache` (module id + run number). \r\n    - The live cycle of _global_ MEs  is driven by the enter/leave lumi calls (indirectly) and the `cleanupLumi` hook  using the edm feature added in #28562,  #28521 . They are kept in a set of containers indexed by run and lumi number. For `RUN` MEs, the lumi number is 0; for `JOB` MEs, run and lumi are zero. The special pair `(0,0)` is also used for _prototypes_: Global MEs that are not currently associated to any run or lumi, but can (and _have to_, for the legacy guarantees) be recycled once a run or lumi starts. \r\n    - If there are no concurrent lumisections, both _local_ and _global_ MEs live for the entire job and are always connected in the same way, which means all legacy interactions continue to work. `assertLegacySafe` (enabled by default) checks for this condition and crashes the job if it is violated.\r\n- Harvesting controlled by _Scope_.\r\n    - In the old `DQMStore`, the handling of per-job vs. per-run historgrams as well as the handling of per-lumi histograms in online, offline, and harvesting is very confusing.\r\n    - To clarify this situation, we introduce the concept of _Scope_:\r\n        - The _scope_ of a ME can be one of `JOB`, `RUN`, or `LUMI`.\r\n        - The _scope_ defines how long a _global_ ME should be used before it is saved and replaced with a new histogram.\r\n        - The _scope_ must be set during booking.\r\n    - By default, the _scope_ for MEs is `RUN`.\r\n        - Code can explicitly use `IBooker::setScope()` to change the scope to e.g. `LUMI`. This replaces the old `setLumiFlag`.\r\n        - When setting `saveByLumi` option in the `DQMStore`, the default scope changes to `LUMI` for all modules that can support per-lumi saving. It could still be manually overridden in code.\r\n        - In harvesting, the default scope is `JOB`. This works for single-run as well as multi-run harvesting, and emulates the old behavior. Moving to scope `RUN` for non-multi-run harvesting would be cleaner, but requires bigger changes to existing code.\r\n    - When harvesting, we expect histograms to get merged. This merging can be controlled using a single option in `DQMRootSource`: `reScope`. This option sets the _finest allowed scope_ when reading histograms from the input files.\r\n        - When just merging files (e.g. in the DQMIO merge jobs), `reScope` is set to `LUMI`. The scope of MEs is not changed, histograms are only merged if a run is split over multiple files.\r\n        - When harvesting, `reScope` is set to `RUN`. Now, MEs saved with scope `LUMI` will be switched to scope `RUN` and merged. The harvesting modules can observe increasing statistics in the histogram as a run is processed (like in online DQM).\r\n        - For multi-run harvesting, `reScope` is set to `JOB`. Now, even `RUN` histograms are merged. This is the default, since it also works for today's single-run harvesting jobs.\r\n- In-order harvesting.\r\n    - Harvesting jobs are always processed sequentially, like the data was taken: runs and lumisections are processed in increasing order. This is implemented in `DQMRootSource`.\r\n- Thread-safe `MonitorElement`s.\r\n    - There is (effectively) only one type of ME, and it uses locking on a local lock to allow safe access from multiple threads.\r\n    - There are three different namespaces (`reco`, `harvesting`, `legacy`) providing this ME type, however the `reco` version does not expose some non-thread-safe APIs.\r\n    - The `MonitorElement` can _own_ the `MonitorElementData` that holds the actual histogram (that is the case for _global_ MEs), or _share_ it with one ME that owns the data and others that don't (this is the case for _local_ MEs).\r\n    - The `MonitorElementData` does not provide an API. It is always wrapped in a `MonitorElement`.\r\n    - The `MonitorElement` has _no_ state, apart from the pointer to the data and the `is_owned` flag.\r\n        - Actually, it does have some state in the `DQMNet::CoreObject`, which is present in the `MonitorElement` to remain compatible with `DQMNet` for online DQM. The values there (dir, name, flags, qtests) are to be considered cached copies of the \"real\" values in `MonitorElementData`. The dir/name copy in the `CoreObject` is also used as a set index for the `std::set`s in the `DQMStore`, since it remains available even when the `MonitorElementData` is detached from local MEs (e.g. between lumisections).\r\n    - The `MonitorElement` still allows access to the underlying ROOT object (`getTH1()`), but this is unsafe and should be avoided whenever possible. However, there is no universal replacement yet, and DQM framework code uses direct access to the ROOT object in many places.\r\n- Debugging tools: To understand how a ME is handled, set the `process.DQMStore.trackME = cms.untracked.string(\"<ME Name>\")` option in the config file.\r\n      - The `DQMStore` will then log all life cycle events affecting MEs matching this name. This does not include things done to the ME (like filling -- the `DQMStore` is not involved there), but it does include creation, reset, recycling, and saving of MEs.\r\n      - The matching is a sub-string match on the full path, so it is also possible to watch folders or groups of MEs.\r\n      - For the more difficult cases, it can make sense to put a debug breakpoint (`std::raise(SIGNINT)`) inside `DQMStore::debugTrackME` to inspect the stack when a certain ME is created/modified.\r\n      - The previous functionality of logging the caller for all booking calls also still exists and can be enabled by setting `process.DQMStore.verbose = 4`.\r\n\r\n#### PR validation:\r\n\r\nPasses the relevant unit tests and also some `runTheMatrix`workflows. \r\n\r\nKnown broken:\r\n- Anything with `DQMStore::load()` (should be unused, but there still is code referring to it, related to references. This can be removed, since references are gone for a while now.)\r\n- Standard Configuration files mostly still work, but need clean up. The DQMStore does not accept many options any more. Esp. check around `DQMRootSource` related to single/multi run harvesting.\r\n\r\nOther flaws:\r\n- Some parts  of the `MonitorElement` implementation can be moved around/removed.", "branch": "master", "changed_files": 169, "closed_at": "1581355702", "comments": 161, "commits": 112, "created_at": "1576244849", "deletions": 5555, "labels": ["alca-approved", "code-checks-approved", "comparison-available", "core-approved", "dqm-approved", "hlt-approved", "l1-pending", "operations-approved", "orp-approved", "pending-signatures", "reconstruction-approved", "tests-approved", "urgent"], "merge_commit_sha": "7bf830bbb5f57be6673227056342a5adf8c88567", "merged_at": "1581355702", "merged_by": "cmsbuild", "milestone": "CMSSW_11_1_X", "number": 28622, "release-notes": [], "review_comments": 33, "state": "closed", "title": "DQM: new DQMStore.", "updated_at": "1581355702", "user": "schneiml"}