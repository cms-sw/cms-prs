{"additions": 4088, "auther_ref": "torch-alpaka-pr", "auther_sha": "a175708c52b57f0d80802ce05813bdbdd81c6a52", "author": "lukaszmichalskii", "body": "#### PR description:\r\n\r\nThis PR enables seamless integration between PyTorch and the Alpaka-based heterogeneous computing backend, supporting inference workflows with usage of `pytorch` library with `PortableCollection`s objects. It provides:\r\n- Compatibility with Alpaka device/queue abstractions.\r\n- Support for automatic conversion of optimized SoA to torch tensors, with memory blobs reusage.\r\n- Support for both just-in-time (JIT) and ahead-of-time (AOT) model execution (Beta version for AOT).\r\n- Single-threading and CUDA stream management are handled by `Guard` objects specialized for each supported backend.\r\n\r\nThis implementation was presented and discussed at Core Software Meeting: https://indico.cern.ch/event/1538634/\r\n\r\n#### PR validation:\r\n\r\nIncluded demonstration code of interoperability between `SoA` constructs with `PyTorch` C++ API and CMSSW environment in `plugins` and `test` packages.\r\n\r\n### PyTorch Ahead-of-time compilation\r\n\r\nThis pull request also investigates AOT compilation strategy but is in beta version (proof of concept) not yet ready for production usage.\r\n\r\n### GPU support\r\nCUDA backend is supported and tested, ROCm is not yet supported: [cms-sw/cmsdist#9786](https://github.com/cms-sw/cmsdist/pull/9786)\r\n\r\nFYI @valsdav @ericcano @felicepantaleo @chrisizeh @leobeltra", "branch": "master", "changed_files": 66, "comments": 15, "commits": 3, "created_at": "1745997609", "deletions": 335, "labels": ["pending-signatures", "tests-rejected", "orp-pending", "new-package-pending", "code-checks-approved", "ml-pending", "changes-dataformats"], "milestone": "CMSSW_15_1_X", "number": 47984, "release-notes": [], "review_comments": 0, "state": "open", "title": "Integrating PyTorch in Alpaka heterogeneous core", "updated_at": "1746638263", "user": "lukaszmichalskii"}