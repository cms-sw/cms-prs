{"additions": 4684, "auther_ref": "torch-alpaka-pr", "auther_sha": "cd3feb9e1d94f799bd984bd87ad53a74bb72930f", "author": "lukaszmichalskii", "body": "#### PR description:\r\n\r\nThis PR enables seamless integration between PyTorch and the Alpaka-based heterogeneous computing backend, supporting inference workflows with usage of `pytorch` library with `PortableCollection`s objects. It provides:\r\n- Compatibility with Alpaka device/queue abstractions.\r\n- Support for automatic conversion of optimized SoA to torch tensors, with memory blobs reusage.\r\n- Support for both just-in-time (JIT) and ahead-of-time (AOT) model execution (Beta version for AOT).\r\n- Single-threading and CUDA stream management are handled by `Guard` objects specialized for each supported backend.\r\n\r\nThis implementation was presented and discussed at Core Software Meeting: https://indico.cern.ch/event/1538634/\r\n\r\n#### PR validation:\r\n\r\nIncluded demonstration code of interoperability between `SoA` constructs with `PyTorch` C++ API and CMSSW environment in `plugins` and `test` packages.\r\n\r\n### PyTorch Ahead-of-time compilation\r\n\r\nThis pull request also investigates AOT compilation strategy but is in beta version (proof of concept) not yet ready for production usage.\r\n\r\n### GPU support\r\nCUDA backend is supported and tested, ROCm is not yet supported: [cms-sw/cmsdist#9786](https://github.com/cms-sw/cmsdist/pull/9786)\r\n\r\nFYI @valsdav @ericcano @felicepantaleo @chrisizeh @leobeltra", "branch": "master", "changed_files": 72, "comments": 47, "commits": 1, "created_at": "1745997609", "deletions": 343, "labels": ["pending-signatures", "tests-approved", "orp-pending", "new-package-pending", "code-checks-approved", "heterogeneous-rejected", "ml-approved", "changes-dataformats"], "milestone": "CMSSW_16_0_X", "number": 47984, "release-notes": [], "review_comments": 83, "state": "open", "title": "Integrating PyTorch in Alpaka heterogeneous core", "updated_at": "1757484262", "user": "lukaszmichalskii"}