{"additions": 1326, "auther_ref": "pt3_dnn", "auther_sha": "f1fd6d5c60df05f148cab3431a3fb96b6fdb3673", "author": "SegmentLinking", "body": "#### PR description:\r\n\r\nThis PR introduces an additional DNN to the LST codebase for better fake rejection of pT3 and pT5 objects. The DNN has a similar architecture to the other DNN's already present in LST: https://github.com/cms-sw/cmssw/pull/47618 for T3's and https://github.com/cms-sw/cmssw/pull/46857 for T5's. It uses six input features from the existing pT3 and pT5 cuts and applies an additional DNN-based cut to further reduce the LST fake rate. The reduction in fake rate is most pronounced at high pT in the default (pT > 0.8 GeV) configuration, as shown below. The DNN cut has negligible impacts on timing and efficiency.\r\n\r\nThis PR also adds my training notebook to the codebase, in line with the other DNN notebooks already present.\r\n\r\nA detailed summary of the improvements can be found here: [PR_162.pdf](https://github.com/user-attachments/files/19984352/PR_162.pdf)\r\n\r\nOther minor changes:\r\n1. The rz chi-squared value is now always computed, even for pT3 objects with pT > 5.0 GeV, to avoid overfitting on the previous default value of -1.\r\n2. Minor naming cleanups in `NeuralNetwork.h`.\r\n\r\n![Screenshot 2025-04-30 at 5 02 00PM](https://github.com/user-attachments/assets/303db353-ada3-417b-b4a3-5b24248672ae)\r\n\r\n#### PR validation:\r\n\r\nThis PR was tested on CPU and GPU in the standalone configuration and runs without issue.\r\n", "branch": "master", "changed_files": 9, "comments": 40, "commits": 1, "created_at": "1746040790", "deletions": 63, "labels": ["hlt-approved", "reconstruction-approved", "fully-signed", "tests-approved", "orp-pending", "code-checks-approved", "heterogeneous-approved", "tracking"], "milestone": "CMSSW_15_1_X", "number": 47995, "release-notes": [], "review_comments": 0, "state": "open", "title": "Add pT3 DNN to LST for Improved Fake Rejection", "updated_at": "1746763747", "user": "GNiendorf"}