{"additions": 150, "auther_ref": "digiscudasoa_patch_2021_11_17", "auther_sha": "fd1a536dfe4827cccc39dd60dc86feda4eafd058", "author": "czangela", "body": "#### PR description:\r\n\r\nThis is a technical PR that merges memory buffers of `SiPixelDigisCUDA`, to have a single `SoA` buffer. \r\nAlso, output collections are now copied to the `CPU` in a single call. \r\n\r\nThis decreases memory allocation for each thread, the number of certain API calls and improves throughput (measurements carried out in `pixeltrack-standalone framework`).\r\n\r\nOther details:\r\n* release: `CMSSW_12_1_0_pre5`\r\n* machine: `cmg-gpu1080`\r\n* `export CUDA_VISIBLE_DEVICES=4`\r\n\r\n**API calls diff:** (for **9** events)\r\n(measurement done with `nvprof`, output formatted with `awk`, `sort`, `diff`)\r\n|  API name  |       baseline       |  digiscudasoa_patch_2021_11_17  | diff | per event diff | per reco diff |\r\n| :-------------: |  :------------------:  | :---------------------------------------------:| :---:| :-----------------:|:---------------: |\r\n| cudaEventCreateWithFlags | 218 | 206| -12 | | | \r\n| cudaEventDestroy | 218 | 206| -12 | | |\r\n| cudaEventQuery | 1112 | 1032 | -80 | | |\r\n| cudaEventRecord | 1080 | 990 | -90 | | |\r\n| cudaFree | 164 | 160| -4 | | -4|\r\n| cudaFreeHost | 299 | 291 | -8 | | -8 |\r\n| cudaGetDevice | 2654 | 2470 | -184 | | |\r\n| cudaHostAlloc | 298 | 290 | -8 | | -8 |\r\n| cudaMalloc | 148 | 144 | -4 | | -4|\r\n| cudaMemcpyAsync| 490| 454| -36| -4 | |\r\n|cudaSetDevice| 1382| 1315 | -67 | | |\r\n| cudaStreamWaitEvent | 3 | 6 | +3 | | | \r\n\r\n*diff view*\r\n```\r\n-218 cudaEventCreateWithFlags\r\n+206 cudaEventCreateWithFlags\r\n-218 cudaEventDestroy\r\n+206 cudaEventDestroy\r\n-1112 cudaEventQuery\r\n+1032 cudaEventQuery\r\n-1080 cudaEventRecord\r\n+990 cudaEventRecord\r\n-164 cudaFree\r\n+160 cudaFree\r\n-299 cudaFreeHost\r\n+291 cudaFreeHost\r\n-2654 cudaGetDevice\r\n+2470 cudaGetDevice\r\n-298 cudaHostAlloc\r\n+290 cudaHostAlloc\r\n-148 cudaMalloc\r\n+144 cudaMalloc\r\n-490 cudaMemcpyAsync\r\n+454 cudaMemcpyAsync\r\n-1382 cudaSetDevice\r\n+1315 cudaSetDevice\r\n-3 cudaStreamWaitEvent\r\n+6 cudaStreamWaitEvent\r\n```\r\n\r\n**Memory allocation per event thread:**\r\n(measurement done with `nvidia-smi` while running `cmsRun`)\r\n|  threads/streams  |     baseline       |  digiscudasoa_patch_2021_11_17  | difference |\r\n|----------|:-------------:|:------:|:-------------: |\r\n| 1 thread/stream | 611 MiB | 597 MiB | -14 MiB |\r\n| 8 threads/streams |    867 MiB   |  751 MiB | -116 MiB |\r\n| diff - 7 threads | 256 MiB | 154 MiB |  - |\r\n| **per thread** | **36 MiB** | **22 MiB** | **-14MiB** |\r\n\r\nThese measurements show that the **decrease** in **per event** memory allocations **scales with the number of threads** and is approximately **39%**.\r\n\r\n**Throughput**\r\n(in `pixeltrack-standalone` framework [applying the same changes](https://github.com/czangela/pixeltrack-standalone/tree/cudadev_digis_patch_2021_11_18))\r\n```\r\n# before\r\n$  for N in 1 2 3 4; do taskset -c 0-15,32-47 ./cudadev  --numberOfThreads 16 --maxEvents 10000; done\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.657476e+00 seconds, throughput 1155.07 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.695556e+00 seconds, throughput 1150.01 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.730811e+00 seconds, throughput 1145.37 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.742207e+00 seconds, throughput 1143.88 events/s.\r\n\r\n# after\r\n$  for N in 1 2 3 4; do taskset -c 0-15,32-47 ./cudadev  --numberOfThreads 16 --maxEvents 10000; done\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.489208e+00 seconds, throughput 1177.97 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.525742e+00 seconds, throughput 1172.92 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.563654e+00 seconds, throughput 1167.73 events/s.\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nProcessed 10000 events in 8.579456e+00 seconds, throughput 1165.58 events/s.\r\n```\r\n**Before average: 1171,05 events/s**\r\n**After average: 1148,5825 events/s**\r\n`1171,05 / 1148,5825 - 1 = 1,956% ~ 2% speedup`\r\n\r\n#### PR validation:\r\n\r\nThe reconstruction remains the same from the physics point of view.\r\n\r\n**Validation in pixeltrack-standalone framework:**\r\n```\r\n$ ./cudadev --histogram --validation --numberOfThreads 16 --maxEvents 10000\r\nFound 1 devices\r\nProcessing 10000 events, of which 16 concurrently, with 16 threads.\r\nCountValidator: all 10000 events passed validation\r\n Average relative track difference 0.000857969 (all within tolerance)\r\n Average absolute vertex difference 0.0011 (all within tolerance)\r\nProcessed 10000 events in 7.489605e+01 seconds, throughput 133.518 events/s.\r\n```\r\n\r\n#### if this PR is a backport please specify the original PR and why you need to backport that PR:\r\n\r\nkindly ping @tonydp03 @felicepantaleo @VinInn \r\n", "branch": "master", "changed_files": 10, "comments": 14, "commits": 7, "created_at": "1637310734", "deletions": 131, "labels": ["reconstruction-pending", "pending-signatures", "tests-pending", "orp-pending", "code-checks-approved", "heterogeneous-pending"], "milestone": "CMSSW_12_2_X", "number": 36176, "release-notes": [], "review_comments": 15, "state": "open", "title": "Improve buffer allocation and copies for SiPixelDigisCUDA", "updated_at": "1637742210", "user": "czangela"}