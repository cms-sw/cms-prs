{"additions": 1909, "auther_ref": "pytorch-alpaka", "auther_sha": "b9823c95a9d34d1bdc1273954098381df11edd14", "author": "ericcano", "body": "#### PR description:\r\n\r\nThis draft PR adds support for libtorch to CMSSW in order to run inference in the context of CMSSW's model.\r\nThe main features are:\r\n- automatic wrapping of Alpaka buffers into Torch tensor structures (no copy).\r\n- Running of the inference in a fashion compatible with the CMSSW model: in CUDA, run in a controlled stream (one per test thread in the test program) and on the serial CPU, make sure the inference is limited to the calling thread and does not spawn additional ones.\r\n\r\n#### PR validation:\r\n\r\nThe test validates the inference output, and show that it is functionnal\r\nThe 4 use cases (Torch sctip / local C++ NN model + CUDA / serial CPU) are functional, and all 4 use cases have been validated in NSight System to validate the threading/stream model is as expected.\r\n\r\nI'm back in IT and was in the patratrack hackathon as a last one-off. @valsdav and I will do the follow up of this PR.\r\n", "branch": "master", "changed_files": 20, "comments": 1, "commits": 45, "created_at": "1720796883", "deletions": 0, "labels": ["analysis-pending", "pending-signatures", "tests-pending", "orp-pending", "code-checks-pending", "ml-pending"], "milestone": "CMSSW_14_1_X", "number": 45441, "release-notes": [], "review_comments": 0, "state": "open", "title": "Pytorch alpaka", "updated_at": "1720796925", "user": "ericcano"}